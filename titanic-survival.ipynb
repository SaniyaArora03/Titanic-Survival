{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2965537,"sourceType":"datasetVersion","datasetId":1818188}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Load the Titanic train and test datasets\ntrain = pd.read_csv(\"/kaggle/input/titanic-dataset/Titanic-Dataset.csv\")\ntest = pd.read_csv(\"/kaggle/input/titanic-dataset/Titanic-Dataset.csv\")\n\n#.shape shows number of rows and colums in dataset\nprint(\"train shape:\", train.shape) \nprint(\"test shape:\", test.shape)\n\n#shows column names, non-null values,data types\ntrain.info()\n \nprint(\"\\nMissing values (train):\\n\", train.isnull().sum())    #counts sum of null values\nprint(\"\\nSurvival value counts:\\n\", train['Survived'].value_counts(normalize=True))  \n#train['Survived'] → Selects the target column (0 = died, 1 = survived).\n#.value_counts(normalize=True) → Shows percentage distribution instead of raw counts.\n#Helps detect class imbalance.\n\n#VISUALISE SURVIVAL COUNTS\nsns.countplot(x='Survived', data=train)\nplt.title('Survived counts')\nplt.show()\n#sns.countplot → Makes a bar chart showing count of passengers who survived vs. didn’t survive.\n#plt.title() → Adds a title.\n#.show() → Displays the plot.\n\n#VISUALISE SURVIVAL RATE BY GENDER\nsns.countplot(x='Sex',hue='Survived',data=train)\n\n#AGE DISTRIBUTION BY PASSENGER CLASS\nsns,boxplot(x='Pclass',y='Age',data=train)\nplt.title('Age by Pclass')\nplt.show()\n\n#DATA PREPROCESSING - FEATURE ENGINEERING\n# Step 3 - simple cleaning\ntrain2 = train.copy()\ntest2 = test.copy()\n\n# Save PassengerId for final submission\ntest_passenger_ids = test2['PassengerId']\n\n# Fill common missing values (simple baseline)\ntrain2['Age'].fillna(train2['Age'].median(), inplace=True)\ntest2['Age'].fillna(test2['Age'].median(), inplace=True)\ntrain2['Embarked'].fillna(train2['Embarked'].mode()[0], inplace=True)\ntest2['Fare'].fillna(test2['Fare'].median(), inplace=True)\n\n# Drop Cabin (lots missing) and Name/Ticket/PassengerId for model input\ntrain2.drop(['Cabin'], axis=1, inplace=True)\ntest2.drop(['Cabin'], axis=1, inplace=True)\n\nfull = pd.concat([train2.assign(dataset='train'), test2.assign(dataset='test')], sort=False)\n#concats both datasets and assigns which is trained and which is test, sort=false keeps it in same order without sorting\n\nfull['Title'] = full['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\n#Goal: Captures social title, which is correlated with age, gender, and survival odds.\n\n# Map rare titles to common groups\n#Prevents very small categories that could confuse the model.\ntitle_map = {\n    'Mlle':'Miss', 'Ms':'Miss', 'Mme':'Mrs',\n    'Lady':'Rare','Countess':'Rare','Capt':'Rare','Col':'Rare','Don':'Rare','Dr':'Rare','Major':'Rare',\n    'Rev':'Rare','Sir':'Rare','Jonkheer':'Rare','Dona':'Rare'\n}\nfull['Title'] = full['Title'].replace(title_map)\n\n#\nfull['FamilySize'] = full['SibSp'] + full['Parch'] + 1  \nfull['IsAlone'] = (full['FamilySize']==1).astype(int)\n#SibSp = siblings/spouses aboard, Parch = parents/children aboard.\n#+1 includes the passenger themselves.\n#IsAlone = binary flag → 1 if no family aboard, else 0.\n\nfull['Age'] = full.groupby('Title')['Age'].transform(lambda x: x.fillna(x.median()))\n#Groups passengers by Title (e.g., Mr, Miss, Rare).\n#Fills missing ages with the median age for that title.\n\nfull['Fare'] = full.groupby('Pclass')['Fare'].transform(lambda x: x.fillna(x.median()))\n\n#Turns each category into binary columns (0/1).\n#drop_first=True → Avoids multicollinearity by dropping one category from each set.\n#Example: Sex → only Sex_male (female implied when 0).\nfull = pd.get_dummies(full, columns=['Sex','Embarked','Title'], drop_first=True)\n\n#drop unused non numeric colums\nfull.drop(['Name','Ticket','PassengerId','dataset'],axis=1,inplace=True)\n\ntrain_fe=full.loc[full.loc[full['Survived'].notnull()].copy()]\ntest_fe = full.loc[full['Survived'].isnull()].drop('Survived', axis=1).copy()\n#train_fe: Rows with Survived value (original training set).\n#test_fe: Rows without Survived (original test set).\n#Drop Survived from test since we’ll predict it.\n\nX = train_fe.drop('Survived', axis=1)\ny = train_fe['Survived'].astype(int)\n#X: All columns used to predict survival and drop the actual survival column ie features\n#y:the actual survival column \n\nprint(\"X shape:\", X.shape)\nprint(\"test_fe shape:\", test_fe.shape)\n\n#ACTUAL MODEL TRAINING\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import  accuracy_score, classification_report, confusion_matrix\n\n#splitting data into training and validation\nX_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.2,random_state=42, stratify=y)\n\n#LOGISTIC REGRESSION\nlr=LogisticRegression(max_iter=1000, random_state=42)\nlr.fit(X_train,y_train)\nprint(\"LR val acc:\", accuracy_score(y_val, lr.predict(X_val)))\n\n#RANDOM FOREST\nrf=RandomForestClassifier(n_estimators=100, random_state=42)\nrf.fit(X_train, y_train)\nyhat = rf.predict(X_val)\n\n#accuracy score\nprint(\"RF val acc:\", accuracy_score(y_val, yhat)) \nprint(classification_report(y_val,yhat))\n\n#CROSS VALIDATION\nfrom sklearn.model_selection import cross_val_score\n#purpose:to check how well random forest model works to detect overfitting/underfitting\nprint(\"RF CV mean:\", cross_val_score(rf, X, y, cv=5).mean())\ncross_val_score → Performs cross-validation.\n\n#rf → This is your Random Forest model (already trained or ready to train).\n#X → Features (input data without the target).\n#y → Target variable (Survived in Titanic).\n#cv=5 → 5-fold cross-validation:\n   #The dataset is split into 5 equal parts.\n   #The model trains on 4 parts and tests on the remaining 1 part.\n   #This repeats 5 times so every part gets tested once.\n   #.mean() → Takes the average of the 5 test scores to give a more reliable accuracy measure than a single train-test split.\n\nimportances=pd.Series(rf.feature_importances_,index=X.columns).sort_values(ascending=False))\n#rf.feature_importances_ → After training, Random Forest can tell you how important each feature was for making predictions.\n#pd.Series(..., index=X.columns) → Makes a Pandas Series where:\n   #Values = importance scores from the model\n   #Index = feature names\n   #.sort_values(ascending=False) → Sorts so the most important feature is at the top.\n\ntest_fe_aligned = test_fe.reindex(columns=X.columns, fill_value=0)\n#The test DataFrame has exactly the same columns as X (training features).\n#If a column is missing, it fills it with 0 (meaning that category did not occur for that row).\n\n#training final model\nfinal_model = RandomForestClassifier(n_estimators=200, random_state=42)\nfinal_model.fit(X, y)\n\npred_test = final_model.predict(test_fe_aligned)\n\n\n#final result whether passenger survived or not\nsubmission = pd.DataFrame({\n    'PassengerId': test_passenger_ids,\n    'Survived': pred_test.astype(int)\n})\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Saved submission.csv — upload or submit from Kaggle notebook UI\")\n\n\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}